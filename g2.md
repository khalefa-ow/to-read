# ColBERTv2: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT  
**File Name:** 211201488_1.pdf  
**Link:** [ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT](https://aclanthology.org/2020.sigir-main.39/)  
**Summary:**  
This paper discusses ColBERTv2, a retrieval model that improves the quality and space efficiency of multi-vector representations for search and forum queries. The authors found that using cluster centroids to capture the context-aware semantics of token-level representations significantly reduced the footprint of multi-vector systems. They also found that distilling knowledge from a cross-encoder system improves the quality of multi-vector retrieval. ColBERTv2 outperforms other retrieval models across 28 datasets, achieving state-of-the-art quality with a competitive space footprint.

# CodexDB: GPT-3 Codex for SQL Query Processing  
**File Name:** 2204.08941.pdf  
**Summary:**  
This paper describes CodexDB, a prototype system that uses GPT-3 Codex to generate code for processing SQL queries. CodexDB takes a SQL query and a database catalog as input and generates code that executes the query on the database. The system employs a planner to translate the query into a series of natural language processing steps, which are then fed to GPT-3 Codex as a prompt, allowing for code generation that implements the query result processing.

# A Framework for Composing Language Models and Retrieval Models for Multi-Hop Question Answering  
**File Name:** 221214024_1.pdf  
**Link:** [Reading Wikipedia to answer open-domain questions](https://aclanthology.org/P17-1171)  
**Summary:**  
This paper presents a framework for composing language models (LMs) and retrieval models (RMs) to perform complex multi-hop question answering. It is based on a domain-specific programming language (DSP) that enables users to define pipelines for text transformations. DSP programs facilitate annotation bootstrapping and generate chain-of-thought rationales for individual prompts, generalizing prior methods for multi-hop reasoning.

# Using Large Language Models in Interactive Environments  
**File Name:** 230202662.pdf  
**Summary:**  
This study investigates the use of large language models (LLMs) as policies in interactive environments. The researchers fine-tune an LLM using Proximal Policy Optimization (PPO) and Behavioral Cloning, demonstrating its ability to learn tasks in BabyAI-Text environments. The system uses a simple prompt template that includes the task description, current observations, and possible actions to optimize LLM performance in dynamic environments.

# Supporting User Feedback in Knowledge Graph Chatbots  
**File Name:** 230206466.pdf  
**Summary:**  
This paper discusses the importance of supporting different types of user feedback in knowledge graph (KG) chatbots. The authors propose incorporating explainability features to improve feedback quality and accuracy. They suggest ways for KG chatbots to handle feedback, including clarification questions, KG updates, and incorporating temporary information for ongoing conversations.

# DashQL: A SQL Dialect for Interactive Data Exploration  
**File Name:** 2306.03714.pdf  
**Summary:**  
DashQL is introduced as a SQL dialect designed for interactive data exploration, scalable dashboards, and workflow development. It extends SQL with statements such as SET, INPUT, FETCH, LOAD, and VISUALIZE, enabling users to define global properties, handle runtime input, and create visualizations. DashQL's support for remote predicate pushdown and adaptive materialization is demonstrated through a workflow example.

# LinguaManga: Low-Code Entity Resolution with LLMs  
**File Name:** 2306.11702.pdf  
**Summary:**  
LinguaManga is a system that enables low-code and no-code users to perform entity resolution tasks. It provides customizable pipelines and built-in templates for various tasks, along with code generation capabilities. The system allows users to enhance or create ML-based operators for their needs, demonstrated through applications like name extraction from multilingual data.

# Prong: A Structure Editor for Domain-Specific Languages  
**File Name:** 2307.11260 2.pdf, 2307.11260.pdf  
**Summary:**  
Prong is a structure editor that improves text manipulation in domain-specific languages (DSLs). It provides a dynamic menu with type information, structural manipulation tools, and DSL-aware suggestions. Users can edit text directly or through the menu, enhancing efficiency and accuracy in DSL development.

# ADOPT: Adaptive Data Stream Processing  
**File Name:** 2307.16540.pdf  
**Summary:**  
ADOPT is a system for adaptive data stream processing that dynamically adjusts query execution plans based on the characteristics of incoming data. It outperforms existing approaches for acyclic and cyclic queries. The paper presents a formal analysis of ADOPT's algorithm and its performance across different datasets.

# CAESURA: Multimodal Query Translation for Data Retrieval  
**File Name:** 2308.03424.pdf  
**Summary:**  
CAESURA is a system that translates natural language queries into logical plans for retrieving data from multimodal databases. The system uses LLMs to generate query plans and maps them to physical operators, supporting complex queries involving both text and image data. CAESURA is evaluated on two datasets, showcasing its ability to handle multimodal queries effectively.

# Automating Data Transformation for Machine Learning with Multiple Agents  
**File Name:** 2308.05637.pdf  
**Summary:**  
This paper presents a framework that uses multiple agents to automate data transformation for machine learning tasks. Specialized agents for data exploration, code generation, code execution, and model training work together to refine data transformations iteratively, making machine learning data preparation more efficient and reducing the workload for data scientists.

# DSPy: A Domain-Specific Programming Language for Large Language Models  
**File Name:** 2310.03714.pdf  
**Summary:**  
DSPy is introduced as a domain-specific programming language for composing and manipulating large language models (LLMs). It allows users to define transformation pipelines called "signatures," reducing the need for complex string manipulation. DSPy includes modules for popular prompting techniques like ChainOfThought and ProgramOfThought, making it easier to build modular LLM programs.

# Proceedings of the ACM Management of Data Conference (SIGMOD)  
**File Name:** 3588957.pdf  
**Summary:**  
This document is the proceedings of the ACM Management of Data (SIGMOD) conference, which includes papers on topics such as database systems, data management, and related areas of research.

# Fine-Tuning LLM for a "Lord of the Rings" Storyteller  
**File Name:** fineTune LLM Lord of the rings.pdf  
**Summary:**  
This tutorial explains how to fine-tune an open-source large language model (LLM), specifically Bloom-3B, on the "Lord of the Rings" book to create a personalized storyteller. The process includes steps for data extraction, preparation, and model training, as well as optimization techniques like quantization and PEFT LoRA adapters for faster model fine-tuning.

# Mutable: A Modern DBMS for Research and Prototyping  
**File Name:** Haffner, Dittrich - mutable_ A Modern DBMS for Research and Fast Prototyping @CIDR2023.pdf  
**Summary:**  
This paper introduces Mutable, a modern database management system (DBMS) designed for research and rapid prototyping. Mutable simplifies experimentation through descriptive YAML files that define experiment details and workloads. It also supports multiple database systems and custom connectors, making it an efficient tool for fast prototyping in research environments.

# J-Logic: A Logic for Querying JSON Data  
**File Name:** J-Logic_a_Logic_for_Querying_JSON.pdf  
**Summary:**  
J-Logic is a logic designed for querying JSON data. It visualizes JSON objects as trees, where edges represent keys and leaves represent atomic values. This representation allows for a complete description of a JSON object by listing all possible paths and values, aiding in efficient querying and processing of JSON data.

# Cost Estimation in Database Systems  
**File Name:** LAWAL_2021_archivage (1).pdf  
**Summary:**  
This paper examines cost estimation techniques in database systems, including methods for statistical profiling, selectivity estimation, and the propagation of costs through query plans. It also explores the use of graph summaries for efficient query processing, specifically in the context of recursive queries over graph datasets.

# Physical Database Design for Document Stores  
**File Name:** PhD_Thesis.pdf  
**Summary:**  
This thesis focuses on physical database design for document stores, particularly for semi-structured data. It reviews the challenges in optimizing these systems and presents a novel approach to physical database design. The work introduces concepts like collection summarization using a data pilot and demonstrates experimental results for improving storage and query performance in document stores.

# Optimizing Query Cost Estimation in Document Stores  
**File Name:** TMLDH1de1.pdf  
**Summary:**  
This paper discusses optimizing physical database design for semi-structured data in document stores, with a focus on improving storage and retrieval performance. It presents a cost model for random access queries, validated using systems like Couchbase Server and MongoDB. The study also introduces DocDesign, a tool that uses this cost model to recommend optimal designs for document stores.

# Benchmarking Cloud Serving Systems  
**File Name:** argo-long.pdf  
**Link:** [Benchmarking Cloud Serving Systems with YCSB](https://dl.acm.org/doi/abs/10.1145/1807128.1807152)  
**Link:** [Storing Semistructured Data with Stored](https://dl.acm.org/doi/10.1145/304181.304199)  
**Summary:**  
This paper reviews benchmarking techniques for cloud serving systems, with references to important works such as "Benchmarking Cloud Serving Systems with YCSB" and "Storing Semistructured Data with Stored." These papers explore performance evaluation and storage management for cloud databases and semi-structured data, respectively.

# ColBERTv2: Efficient Passage Search  
**File Name:** colbertv2.pdf  
**Link:** [SPlade v2: Sparse Lexical and Expansion Model for Information Retrieval](https://arxiv.org/abs/2109.10086)  
**Link:** [SPlade: Sparse Lexical and Expansion Model for First Stage Ranking](https://dl.acm.org/doi/10.1145/3404835.3462815)  
**Link:** [Unsupervised Corpus-Aware Language Model Pre-training for Dense Passage Retrieval](https://arxiv.org/abs/2108.05540)  
**Summary:**  
This paper elaborates on ColBERTv2, an effective and efficient passage search model using contextualized late interaction over BERT. It discusses techniques for improving retrieval quality and space efficiency, alongside references to related works like SPlade, which focuses on sparse lexical models for information retrieval and dense passage retrieval pre-training.
